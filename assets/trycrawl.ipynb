{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/duongphuonggiang/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from llm.llm.gemini import Gemini\n",
    "from llm.llm_utils import get_code_from_text_response, get_json_from_text_response\n",
    "llm = Gemini()\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobScraperr:\n",
    "    def __init__(self, base_url, output_csv):\n",
    "        self.base_url = base_url\n",
    "        self.output_csv = output_csv\n",
    "        self.driver = self._initialize_driver()\n",
    "\n",
    "        self.df = pd.DataFrame(columns=[\n",
    "            \"Job ID\", \"Title\", \"Link\", \"Job_Type\", \"Job_Location\", \n",
    "            \"Job_Category\", \"Salary\", \"Experience_Level\", \"Years_of_Experience\",\n",
    "            \"Main_Job_Description\", \"Candidate_Experience_Requirements\",  \"Candidate_soft_skill_Requirements\", \"Candidate_technical_Requirements\", \"Candidate_degree_Requirements\",\"Benefits\", \n",
    "            \"Additional_Notes\", \"Industry\", \"Address\", \"Academic_Degree\", \n",
    "            \"Sex_Requirement\", \"Degree_Level\", \n",
    "            \"Age_Requirement\"\n",
    "        ])\n",
    "        if not os.path.exists(output_csv):\n",
    "            self.df.to_csv(output_csv, index=False)\n",
    "\n",
    "    def _initialize_driver(self):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--no-sandbox\")\n",
    "        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"--disable-extensions\")\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "        return driver\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Clean and standardize extracted text.\"\"\"\n",
    "        text = re.sub(r'<[^>]+>', '', text)  \n",
    "        text = text.replace('\\n', ' ').replace('<br>', ' ').replace('/', ' ').replace(\"*\",'').replace('•','')\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()  \n",
    "        return text\n",
    "\n",
    "    def get_job_details_from_gemini(self, html_content):\n",
    "        prompt = (\n",
    "            f\"The following HTML contains a job posting:\\n\\n{html_content}\\n\\n\"\n",
    "            f\"Extract the full text content of each specified section in JSON format. Clean the data by removing any unnecessary characters such as '/', '\\\\n', '<br>', and other HTML tags, bullet points (e.g., '-', '*', '•'), and other escape sequences. \"\n",
    "            f\"Ensure that the content in each field uses ':' to separate key-value relationships (e.g., 'Key: Value') and ';' to separate items in a list (e.g., 'Item1; Item2; Item3'). \"\n",
    "            f\"Return the content as plain text without formatting or unnecessary characters. If a section is missing, return 'Not available' as the value.\\n\\n\"\n",
    "            f\"Combine the 'Years of Experience' and 'Experience Level' fields into 'Candidate Experience Requirements' if they exist. \"\n",
    "            f\"If 'Candidate Experience Requirements' already contains content, append 'Years of Experience' and 'Experience Level' to it. If no data exists for these fields, leave the original field as is.\\n\\n\"\n",
    "            f\"Expected JSON output:\\n\"\n",
    "            f\"{{\\n\"\n",
    "            f\"    \\\"Job_Type\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Job_Location\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Job_Category\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Main_Job_Description\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Experience_Level\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Years_of_Experience\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Candidate_Experience_Requirements\\\": \\\"Candidate_Experience_Requirement; Years_of_Experience: [Value] and Experience_Level: [Value]\\\" if available, else keep original content,\\n\"\n",
    "            f\"    \\\"Candidate_soft_skill_Requirements\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Candidate_technical_skill_Requirements\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Candidate_degree_Requirements\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Benefits\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Additional_Notes\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Industry\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Salary\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Address\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Academic_Degree\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Sex_Requirement\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Degree_Level\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Age_Requirement\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Job_Date-open\\\": \\\"\\\",\\n\"\n",
    "            f\"    \\\"Job_Date-end\\\": \\\"\\\"\\n\"\n",
    "            f\"}}\"\n",
    "        )\n",
    "\n",
    "\n",
    "        message = [\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': 'You must extract the content in JSON format and translate into english'\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = llm(message) \n",
    "        temp_cv = self.get_json_from_text_response(response)\n",
    "        return temp_cv\n",
    "\n",
    "    def get_json_from_text_response(self, response):\n",
    "        \"\"\"Extract JSON from text response.\"\"\"\n",
    "        cleaned_response = response.strip().lstrip(\"```json\").rstrip(\"```\").strip()\n",
    "\n",
    "        try:\n",
    "            json_data = json.loads(cleaned_response)\n",
    "            if isinstance(json_data, dict):\n",
    "                return {k: self.clean_text(v) if isinstance(v, str) else v for k, v in json_data.items()}\n",
    "            else:\n",
    "                return self._default_job_detail()\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Failed to parse JSON from response.\")\n",
    "            return self._default_job_detail()\n",
    "\n",
    "    def _default_job_detail(self):\n",
    "        return {col: 'Not available' for col in self.df.columns if col not in [\"Job ID\", \"Title\", \"Link\"]}\n",
    "\n",
    "    def extract_job_detail(self, job_link, job_data):\n",
    "        self.driver.execute_script(\"window.open(arguments[0], '_blank');\", job_link)\n",
    "        self.driver.switch_to.window(self.driver.window_handles[1])\n",
    "        time.sleep(2)\n",
    "\n",
    "        try:\n",
    "            container_wrap = self.driver.find_element(By.CSS_SELECTOR, \"div.container-wrap\")\n",
    "            header = self.driver.find_element(By.CSS_SELECTOR, \"header.noo-page-heading\")\n",
    "            combined_html = header.get_attribute(\"outerHTML\") + container_wrap.get_attribute(\"outerHTML\")\n",
    "\n",
    "            job_detail = self.get_job_details_from_gemini(combined_html) \n",
    "            \n",
    "            job_detail.update(job_data)\n",
    "\n",
    "            if job_detail:\n",
    "                self.append_to_df(job_detail)\n",
    "\n",
    "            self.driver.close()\n",
    "            self.driver.switch_to.window(self.driver.window_handles[0])\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract job detail for link {job_link}: {e}\")\n",
    "            self.driver.close()\n",
    "            self.driver.switch_to.window(self.driver.window_handles[0])\n",
    "\n",
    "    def append_to_df(self, job_detail):\n",
    "        job_df = pd.DataFrame([job_detail])\n",
    "        self.df = pd.concat([self.df, job_df], ignore_index=True)\n",
    "        print(\"Appended job detail to DataFrame.\")\n",
    "\n",
    "    def extract_jobs_from_page(self, job_elements):\n",
    "        for job_element in job_elements:\n",
    "            try:\n",
    "                job_id = job_element.find_element(By.CSS_SELECTOR, \"a.btn-quick-view-popup\").get_attribute(\"data-id\")\n",
    "                title = job_element.find_element(By.CSS_SELECTOR, \"h3 a\").text.strip()\n",
    "                job_link = job_element.find_element(By.CSS_SELECTOR, \"a.job-details-link\").get_attribute(\"href\")\n",
    "\n",
    "                job_data = {\n",
    "                    \"Job ID\": job_id,\n",
    "                    \"Title\": title,\n",
    "                    \"Link\": job_link,\n",
    "                }\n",
    "\n",
    "                self.extract_job_detail(job_link, job_data)\n",
    "                print(f\"Processed job ID: {job_id}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting job: {e}\")\n",
    "\n",
    "    def crawl_jobs(self, start_page, end_page):\n",
    "        for page in range(start_page, end_page + 1):\n",
    "            url = f\"{self.base_url}{page}/\"\n",
    "            self.driver.get(url)\n",
    "            time.sleep(1)\n",
    "\n",
    "            try:\n",
    "                WebDriverWait(self.driver, 5).until(\n",
    "                    EC.visibility_of_all_elements_located((By.CSS_SELECTOR, \".noo-job-item.noo_job\"))\n",
    "                )\n",
    "                job_elements = self.driver.find_elements(By.CSS_SELECTOR, \".noo-job-item.noo_job\")\n",
    "                print(f\"Found {len(job_elements)} jobs on page {page}\")\n",
    "                \n",
    "                self.extract_jobs_from_page(job_elements)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading page {page}: {e}\")\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "        self.driver.quit()\n",
    "        self.save_to_csv()\n",
    "        print(f\"Data saved to {self.output_csv}\")\n",
    "\n",
    "    def save_to_csv(self):\n",
    "        self.df.to_csv(self.output_csv, index=False)\n",
    "        print(\"Data saved to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:38:50,108 - INFO - ====== WebDriver manager ======\n",
      "2024-11-26 17:38:50,410 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-11-26 17:38:50,656 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2024-11-26 17:38:50,830 - INFO - Driver [/Users/duongphuonggiang/.wdm/drivers/chromedriver/mac64/131.0.6778.85/chromedriver-mac-arm64/chromedriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 jobs on page 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:39:10,161 - INFO - Completion time of gemini-1.5-flash-002: 8.55342698097229s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 81003\n",
      "candidates_token_count: 381\n",
      "total_token_count: 81384\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 61009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:39:22,180 - INFO - Completion time of gemini-1.5-flash-002: 9.840788841247559s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78526\n",
      "candidates_token_count: 460\n",
      "total_token_count: 78986\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:39:41,211 - INFO - Completion time of gemini-1.5-flash-002: 16.81583595275879s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78699\n",
      "candidates_token_count: 536\n",
      "total_token_count: 79235\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:39:57,737 - INFO - Completion time of gemini-1.5-flash-002: 14.305126905441284s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78933\n",
      "candidates_token_count: 607\n",
      "total_token_count: 79540\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:40:14,329 - INFO - Completion time of gemini-1.5-flash-002: 13.330347061157227s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79018\n",
      "candidates_token_count: 794\n",
      "total_token_count: 79812\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:40:27,581 - INFO - Completion time of gemini-1.5-flash-002: 11.093473196029663s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79076\n",
      "candidates_token_count: 797\n",
      "total_token_count: 79873\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:40:37,956 - INFO - Completion time of gemini-1.5-flash-002: 8.142744064331055s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78916\n",
      "candidates_token_count: 475\n",
      "total_token_count: 79391\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:40:48,577 - INFO - Completion time of gemini-1.5-flash-002: 8.432646989822388s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79149\n",
      "candidates_token_count: 516\n",
      "total_token_count: 79665\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:41:01,360 - INFO - Completion time of gemini-1.5-flash-002: 10.234374046325684s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79161\n",
      "candidates_token_count: 688\n",
      "total_token_count: 79849\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:41:10,839 - INFO - Completion time of gemini-1.5-flash-002: 7.151581048965454s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78685\n",
      "candidates_token_count: 382\n",
      "total_token_count: 79067\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60799\n",
      "Found 10 jobs on page 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:41:32,052 - INFO - Completion time of gemini-1.5-flash-002: 15.012386083602905s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79011\n",
      "candidates_token_count: 583\n",
      "total_token_count: 79594\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:41:44,335 - INFO - Completion time of gemini-1.5-flash-002: 9.98383116722107s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79377\n",
      "candidates_token_count: 681\n",
      "total_token_count: 80058\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:41:55,126 - INFO - Completion time of gemini-1.5-flash-002: 8.537138938903809s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 81207\n",
      "candidates_token_count: 523\n",
      "total_token_count: 81730\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:42:08,609 - INFO - Completion time of gemini-1.5-flash-002: 11.308289766311646s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79634\n",
      "candidates_token_count: 814\n",
      "total_token_count: 80448\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:42:17,719 - INFO - Completion time of gemini-1.5-flash-002: 6.953402042388916s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 85212\n",
      "candidates_token_count: 385\n",
      "total_token_count: 85597\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:42:27,160 - INFO - Completion time of gemini-1.5-flash-002: 7.261707067489624s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78697\n",
      "candidates_token_count: 401\n",
      "total_token_count: 79098\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:42:37,256 - INFO - Completion time of gemini-1.5-flash-002: 7.941969156265259s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79244\n",
      "candidates_token_count: 487\n",
      "total_token_count: 79731\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:42:49,508 - INFO - Completion time of gemini-1.5-flash-002: 10.072591781616211s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79506\n",
      "candidates_token_count: 723\n",
      "total_token_count: 80229\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:43:02,156 - INFO - Completion time of gemini-1.5-flash-002: 10.460994958877563s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79427\n",
      "candidates_token_count: 727\n",
      "total_token_count: 80154\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:43:12,703 - INFO - Completion time of gemini-1.5-flash-002: 8.386210918426514s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79294\n",
      "candidates_token_count: 506\n",
      "total_token_count: 79800\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60612\n",
      "Found 10 jobs on page 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:43:27,911 - INFO - Completion time of gemini-1.5-flash-002: 8.161062717437744s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78825\n",
      "candidates_token_count: 518\n",
      "total_token_count: 79343\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:43:40,810 - INFO - Completion time of gemini-1.5-flash-002: 9.717228174209595s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78647\n",
      "candidates_token_count: 422\n",
      "total_token_count: 79069\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:43:53,504 - INFO - Completion time of gemini-1.5-flash-002: 10.514534950256348s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78850\n",
      "candidates_token_count: 741\n",
      "total_token_count: 79591\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:44:04,311 - INFO - Completion time of gemini-1.5-flash-002: 8.65385913848877s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 83299\n",
      "candidates_token_count: 547\n",
      "total_token_count: 83846\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:44:13,507 - INFO - Completion time of gemini-1.5-flash-002: 7.012898683547974s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 85157\n",
      "candidates_token_count: 380\n",
      "total_token_count: 85537\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:44:22,743 - INFO - Completion time of gemini-1.5-flash-002: 7.070859909057617s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79085\n",
      "candidates_token_count: 380\n",
      "total_token_count: 79465\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:44:40,128 - INFO - Completion time of gemini-1.5-flash-002: 15.223283052444458s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78743\n",
      "candidates_token_count: 606\n",
      "total_token_count: 79349\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:44:50,460 - INFO - Completion time of gemini-1.5-flash-002: 8.134918928146362s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79592\n",
      "candidates_token_count: 438\n",
      "total_token_count: 80030\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:45:00,271 - INFO - Completion time of gemini-1.5-flash-002: 7.329866886138916s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79062\n",
      "candidates_token_count: 438\n",
      "total_token_count: 79500\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:45:10,051 - INFO - Completion time of gemini-1.5-flash-002: 7.498897314071655s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78741\n",
      "candidates_token_count: 418\n",
      "total_token_count: 79159\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60485\n",
      "Found 10 jobs on page 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:45:25,647 - INFO - Completion time of gemini-1.5-flash-002: 9.232197046279907s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79032\n",
      "candidates_token_count: 626\n",
      "total_token_count: 79658\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:45:46,787 - INFO - Completion time of gemini-1.5-flash-002: 18.059166431427002s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78929\n",
      "candidates_token_count: 592\n",
      "total_token_count: 79521\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:45:56,852 - INFO - Completion time of gemini-1.5-flash-002: 7.877413988113403s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78585\n",
      "candidates_token_count: 421\n",
      "total_token_count: 79006\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:46:08,873 - INFO - Completion time of gemini-1.5-flash-002: 9.853055953979492s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78564\n",
      "candidates_token_count: 526\n",
      "total_token_count: 79090\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:46:19,509 - INFO - Completion time of gemini-1.5-flash-002: 8.438004970550537s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79343\n",
      "candidates_token_count: 543\n",
      "total_token_count: 79886\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:46:29,513 - INFO - Completion time of gemini-1.5-flash-002: 7.8457581996917725s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79211\n",
      "candidates_token_count: 469\n",
      "total_token_count: 79680\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:46:42,107 - INFO - Completion time of gemini-1.5-flash-002: 10.44382095336914s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78910\n",
      "candidates_token_count: 663\n",
      "total_token_count: 79573\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:46:53,370 - INFO - Completion time of gemini-1.5-flash-002: 9.096946001052856s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78412\n",
      "candidates_token_count: 341\n",
      "total_token_count: 78753\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:47:07,602 - INFO - Completion time of gemini-1.5-flash-002: 12.066806077957153s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78943\n",
      "candidates_token_count: 455\n",
      "total_token_count: 79398\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:47:18,645 - INFO - Completion time of gemini-1.5-flash-002: 8.845978736877441s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80409\n",
      "candidates_token_count: 512\n",
      "total_token_count: 80921\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60338\n",
      "Found 10 jobs on page 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:47:35,028 - INFO - Completion time of gemini-1.5-flash-002: 9.992362022399902s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79077\n",
      "candidates_token_count: 690\n",
      "total_token_count: 79767\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:47:46,105 - INFO - Completion time of gemini-1.5-flash-002: 8.481086015701294s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78535\n",
      "candidates_token_count: 552\n",
      "total_token_count: 79087\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:47:57,027 - INFO - Completion time of gemini-1.5-flash-002: 8.760410785675049s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78877\n",
      "candidates_token_count: 593\n",
      "total_token_count: 79470\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:48:06,361 - INFO - Completion time of gemini-1.5-flash-002: 7.181812047958374s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78558\n",
      "candidates_token_count: 414\n",
      "total_token_count: 78972\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:48:20,306 - INFO - Completion time of gemini-1.5-flash-002: 11.789440870285034s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78781\n",
      "candidates_token_count: 490\n",
      "total_token_count: 79271\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:48:30,648 - INFO - Completion time of gemini-1.5-flash-002: 7.477229118347168s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78665\n",
      "candidates_token_count: 456\n",
      "total_token_count: 79121\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:48:44,472 - INFO - Completion time of gemini-1.5-flash-002: 11.670357942581177s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78897\n",
      "candidates_token_count: 798\n",
      "total_token_count: 79695\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:48:54,520 - INFO - Completion time of gemini-1.5-flash-002: 7.891085147857666s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78575\n",
      "candidates_token_count: 491\n",
      "total_token_count: 79066\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:49:05,920 - INFO - Completion time of gemini-1.5-flash-002: 9.214032173156738s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78653\n",
      "candidates_token_count: 517\n",
      "total_token_count: 79170\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:49:20,107 - INFO - Completion time of gemini-1.5-flash-002: 11.973876953125s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79348\n",
      "candidates_token_count: 734\n",
      "total_token_count: 80082\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60214\n",
      "Found 10 jobs on page 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:49:35,712 - INFO - Completion time of gemini-1.5-flash-002: 9.429997682571411s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78917\n",
      "candidates_token_count: 536\n",
      "total_token_count: 79453\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:49:46,220 - INFO - Completion time of gemini-1.5-flash-002: 8.30571699142456s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 81451\n",
      "candidates_token_count: 513\n",
      "total_token_count: 81964\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:49:55,844 - INFO - Completion time of gemini-1.5-flash-002: 7.455184698104858s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80863\n",
      "candidates_token_count: 440\n",
      "total_token_count: 81303\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:50:08,866 - INFO - Completion time of gemini-1.5-flash-002: 10.86169719696045s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79295\n",
      "candidates_token_count: 754\n",
      "total_token_count: 80049\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:50:20,071 - INFO - Completion time of gemini-1.5-flash-002: 9.013404846191406s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79115\n",
      "candidates_token_count: 622\n",
      "total_token_count: 79737\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:50:29,463 - INFO - Completion time of gemini-1.5-flash-002: 7.1510169506073s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78552\n",
      "candidates_token_count: 348\n",
      "total_token_count: 78900\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:50:40,365 - INFO - Completion time of gemini-1.5-flash-002: 8.729723930358887s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80181\n",
      "candidates_token_count: 514\n",
      "total_token_count: 80695\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:50:54,003 - INFO - Completion time of gemini-1.5-flash-002: 11.482275009155273s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79356\n",
      "candidates_token_count: 789\n",
      "total_token_count: 80145\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:51:04,521 - INFO - Completion time of gemini-1.5-flash-002: 8.33965015411377s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78957\n",
      "candidates_token_count: 552\n",
      "total_token_count: 79509\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:51:19,161 - INFO - Completion time of gemini-1.5-flash-002: 12.281008243560791s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 82948\n",
      "candidates_token_count: 565\n",
      "total_token_count: 83513\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60029\n",
      "Found 10 jobs on page 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:51:34,280 - INFO - Completion time of gemini-1.5-flash-002: 8.816658973693848s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80353\n",
      "candidates_token_count: 589\n",
      "total_token_count: 80942\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:51:44,765 - INFO - Completion time of gemini-1.5-flash-002: 8.227988004684448s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79385\n",
      "candidates_token_count: 497\n",
      "total_token_count: 79882\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:51:53,057 - INFO - Completion time of gemini-1.5-flash-002: 6.0768938064575195s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78290\n",
      "candidates_token_count: 302\n",
      "total_token_count: 78592\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:52:02,784 - INFO - Completion time of gemini-1.5-flash-002: 7.572990894317627s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78793\n",
      "candidates_token_count: 450\n",
      "total_token_count: 79243\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:52:12,513 - INFO - Completion time of gemini-1.5-flash-002: 7.540548801422119s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79004\n",
      "candidates_token_count: 449\n",
      "total_token_count: 79453\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:52:25,039 - INFO - Completion time of gemini-1.5-flash-002: 10.344902992248535s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78838\n",
      "candidates_token_count: 714\n",
      "total_token_count: 79552\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:52:36,166 - INFO - Completion time of gemini-1.5-flash-002: 8.650516986846924s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 83095\n",
      "candidates_token_count: 554\n",
      "total_token_count: 83649\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:52:47,636 - INFO - Completion time of gemini-1.5-flash-002: 8.84125304222107s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78975\n",
      "candidates_token_count: 477\n",
      "total_token_count: 79452\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:53:03,917 - INFO - Completion time of gemini-1.5-flash-002: 14.077590227127075s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78347\n",
      "candidates_token_count: 314\n",
      "total_token_count: 78661\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:53:25,766 - INFO - Completion time of gemini-1.5-flash-002: 19.182899951934814s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80939\n",
      "candidates_token_count: 660\n",
      "total_token_count: 81599\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59932\n",
      "Found 10 jobs on page 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:53:58,097 - INFO - Completion time of gemini-1.5-flash-002: 25.9671311378479s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78860\n",
      "candidates_token_count: 529\n",
      "total_token_count: 79389\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:54:07,920 - INFO - Completion time of gemini-1.5-flash-002: 7.640567064285278s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78705\n",
      "candidates_token_count: 467\n",
      "total_token_count: 79172\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:54:18,255 - INFO - Completion time of gemini-1.5-flash-002: 8.150609970092773s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80403\n",
      "candidates_token_count: 475\n",
      "total_token_count: 80878\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:54:29,421 - INFO - Completion time of gemini-1.5-flash-002: 8.57855486869812s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80853\n",
      "candidates_token_count: 543\n",
      "total_token_count: 81396\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:54:43,855 - INFO - Completion time of gemini-1.5-flash-002: 12.227967977523804s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78481\n",
      "candidates_token_count: 466\n",
      "total_token_count: 78947\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:54:53,969 - INFO - Completion time of gemini-1.5-flash-002: 7.882397890090942s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78854\n",
      "candidates_token_count: 466\n",
      "total_token_count: 79320\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:55:05,261 - INFO - Completion time of gemini-1.5-flash-002: 9.129334926605225s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80863\n",
      "candidates_token_count: 464\n",
      "total_token_count: 81327\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:55:15,654 - INFO - Completion time of gemini-1.5-flash-002: 8.214510202407837s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 81097\n",
      "candidates_token_count: 513\n",
      "total_token_count: 81610\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:55:26,254 - INFO - Completion time of gemini-1.5-flash-002: 8.390368938446045s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78937\n",
      "candidates_token_count: 541\n",
      "total_token_count: 79478\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:55:35,635 - INFO - Completion time of gemini-1.5-flash-002: 7.189438819885254s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 82730\n",
      "candidates_token_count: 389\n",
      "total_token_count: 83119\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59714\n",
      "Found 10 jobs on page 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:55:49,838 - INFO - Completion time of gemini-1.5-flash-002: 8.034801006317139s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78357\n",
      "candidates_token_count: 493\n",
      "total_token_count: 78850\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:56:00,144 - INFO - Completion time of gemini-1.5-flash-002: 8.054445028305054s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80488\n",
      "candidates_token_count: 486\n",
      "total_token_count: 80974\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:56:16,226 - INFO - Completion time of gemini-1.5-flash-002: 13.919278144836426s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80241\n",
      "candidates_token_count: 816\n",
      "total_token_count: 81057\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:56:31,586 - INFO - Completion time of gemini-1.5-flash-002: 13.198068857192993s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79161\n",
      "candidates_token_count: 572\n",
      "total_token_count: 79733\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:56:53,951 - INFO - Completion time of gemini-1.5-flash-002: 18.795450687408447s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78949\n",
      "candidates_token_count: 459\n",
      "total_token_count: 79408\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:57:04,144 - INFO - Completion time of gemini-1.5-flash-002: 8.001374959945679s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78733\n",
      "candidates_token_count: 442\n",
      "total_token_count: 79175\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:57:14,487 - INFO - Completion time of gemini-1.5-flash-002: 8.169989824295044s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78768\n",
      "candidates_token_count: 508\n",
      "total_token_count: 79276\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:57:24,647 - INFO - Completion time of gemini-1.5-flash-002: 7.893312215805054s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78579\n",
      "candidates_token_count: 481\n",
      "total_token_count: 79060\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:57:34,699 - INFO - Completion time of gemini-1.5-flash-002: 7.646028995513916s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78606\n",
      "candidates_token_count: 451\n",
      "total_token_count: 79057\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:57:45,618 - INFO - Completion time of gemini-1.5-flash-002: 8.477909088134766s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78796\n",
      "candidates_token_count: 564\n",
      "total_token_count: 79360\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59594\n",
      "Found 10 jobs on page 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:58:02,103 - INFO - Completion time of gemini-1.5-flash-002: 10.215781927108765s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79149\n",
      "candidates_token_count: 746\n",
      "total_token_count: 79895\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:58:12,547 - INFO - Completion time of gemini-1.5-flash-002: 8.264713048934937s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 82605\n",
      "candidates_token_count: 522\n",
      "total_token_count: 83127\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:58:24,528 - INFO - Completion time of gemini-1.5-flash-002: 9.333078145980835s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78485\n",
      "candidates_token_count: 480\n",
      "total_token_count: 78965\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:58:40,407 - INFO - Completion time of gemini-1.5-flash-002: 13.655464887619019s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80867\n",
      "candidates_token_count: 568\n",
      "total_token_count: 81435\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:58:51,075 - INFO - Completion time of gemini-1.5-flash-002: 8.500230073928833s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80725\n",
      "candidates_token_count: 540\n",
      "total_token_count: 81265\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:59:03,947 - INFO - Completion time of gemini-1.5-flash-002: 10.697741031646729s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79062\n",
      "candidates_token_count: 808\n",
      "total_token_count: 79870\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:59:14,596 - INFO - Completion time of gemini-1.5-flash-002: 8.434812307357788s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78691\n",
      "candidates_token_count: 504\n",
      "total_token_count: 79195\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:59:23,817 - INFO - Completion time of gemini-1.5-flash-002: 7.047369956970215s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78186\n",
      "candidates_token_count: 380\n",
      "total_token_count: 78566\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:59:32,249 - INFO - Completion time of gemini-1.5-flash-002: 6.279539346694946s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78332\n",
      "candidates_token_count: 337\n",
      "total_token_count: 78669\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:59:42,691 - INFO - Completion time of gemini-1.5-flash-002: 8.283899068832397s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78551\n",
      "candidates_token_count: 532\n",
      "total_token_count: 79083\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59348\n",
      "Found 10 jobs on page 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:59:56,758 - INFO - Completion time of gemini-1.5-flash-002: 7.7564537525177s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78618\n",
      "candidates_token_count: 465\n",
      "total_token_count: 79083\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:00:12,546 - INFO - Completion time of gemini-1.5-flash-002: 13.371994256973267s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78502\n",
      "candidates_token_count: 413\n",
      "total_token_count: 78915\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:00:26,783 - INFO - Completion time of gemini-1.5-flash-002: 12.033226013183594s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78991\n",
      "candidates_token_count: 919\n",
      "total_token_count: 79910\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:00:39,315 - INFO - Completion time of gemini-1.5-flash-002: 10.34695315361023s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78878\n",
      "candidates_token_count: 732\n",
      "total_token_count: 79610\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:00:49,116 - INFO - Completion time of gemini-1.5-flash-002: 7.642349004745483s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78452\n",
      "candidates_token_count: 457\n",
      "total_token_count: 78909\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:01:01,195 - INFO - Completion time of gemini-1.5-flash-002: 9.916209936141968s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 83462\n",
      "candidates_token_count: 668\n",
      "total_token_count: 84130\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:01:11,988 - INFO - Completion time of gemini-1.5-flash-002: 8.633717060089111s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79027\n",
      "candidates_token_count: 562\n",
      "total_token_count: 79589\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:01:22,702 - INFO - Completion time of gemini-1.5-flash-002: 8.556946992874146s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80742\n",
      "candidates_token_count: 543\n",
      "total_token_count: 81285\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:01:34,786 - INFO - Completion time of gemini-1.5-flash-002: 9.91161298751831s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78864\n",
      "candidates_token_count: 707\n",
      "total_token_count: 79571\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:01:45,470 - INFO - Completion time of gemini-1.5-flash-002: 8.520273923873901s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78878\n",
      "candidates_token_count: 545\n",
      "total_token_count: 79423\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59115\n",
      "Found 10 jobs on page 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:01:59,935 - INFO - Completion time of gemini-1.5-flash-002: 8.112466096878052s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78623\n",
      "candidates_token_count: 414\n",
      "total_token_count: 79037\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:02:13,598 - INFO - Completion time of gemini-1.5-flash-002: 11.391979932785034s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79094\n",
      "candidates_token_count: 627\n",
      "total_token_count: 79721\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:02:24,657 - INFO - Completion time of gemini-1.5-flash-002: 8.863867044448853s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78903\n",
      "candidates_token_count: 579\n",
      "total_token_count: 79482\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:02:34,026 - INFO - Completion time of gemini-1.5-flash-002: 7.118624925613403s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78823\n",
      "candidates_token_count: 410\n",
      "total_token_count: 79233\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:02:44,585 - INFO - Completion time of gemini-1.5-flash-002: 8.369753122329712s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78859\n",
      "candidates_token_count: 533\n",
      "total_token_count: 79392\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:02:54,699 - INFO - Completion time of gemini-1.5-flash-002: 7.917736768722534s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79522\n",
      "candidates_token_count: 482\n",
      "total_token_count: 80004\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:03:07,439 - INFO - Completion time of gemini-1.5-flash-002: 10.566723823547363s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79413\n",
      "candidates_token_count: 652\n",
      "total_token_count: 80065\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:03:19,746 - INFO - Completion time of gemini-1.5-flash-002: 9.658706188201904s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80742\n",
      "candidates_token_count: 655\n",
      "total_token_count: 81397\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:03:29,170 - INFO - Completion time of gemini-1.5-flash-002: 7.21887993812561s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78458\n",
      "candidates_token_count: 405\n",
      "total_token_count: 78863\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:03:42,497 - INFO - Completion time of gemini-1.5-flash-002: 10.596674680709839s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 89176\n",
      "candidates_token_count: 775\n",
      "total_token_count: 89951\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 59007\n",
      "Found 10 jobs on page 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:04:01,836 - INFO - Completion time of gemini-1.5-flash-002: 13.093360900878906s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80606\n",
      "candidates_token_count: 599\n",
      "total_token_count: 81205\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:04:11,455 - INFO - Completion time of gemini-1.5-flash-002: 7.27599310874939s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78495\n",
      "candidates_token_count: 416\n",
      "total_token_count: 78911\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:04:22,198 - INFO - Completion time of gemini-1.5-flash-002: 8.572990894317627s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78765\n",
      "candidates_token_count: 530\n",
      "total_token_count: 79295\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:04:33,017 - INFO - Completion time of gemini-1.5-flash-002: 8.670532703399658s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78799\n",
      "candidates_token_count: 572\n",
      "total_token_count: 79371\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:04:42,733 - INFO - Completion time of gemini-1.5-flash-002: 7.55413293838501s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80244\n",
      "candidates_token_count: 471\n",
      "total_token_count: 80715\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:04:53,747 - INFO - Completion time of gemini-1.5-flash-002: 8.834779262542725s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78544\n",
      "candidates_token_count: 390\n",
      "total_token_count: 78934\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:05:11,503 - INFO - Completion time of gemini-1.5-flash-002: 15.595256805419922s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79260\n",
      "candidates_token_count: 673\n",
      "total_token_count: 79933\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:05:24,468 - INFO - Completion time of gemini-1.5-flash-002: 10.743517875671387s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79102\n",
      "candidates_token_count: 598\n",
      "total_token_count: 79700\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:05:39,416 - INFO - Completion time of gemini-1.5-flash-002: 12.75571894645691s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79016\n",
      "candidates_token_count: 675\n",
      "total_token_count: 79691\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:05:50,231 - INFO - Completion time of gemini-1.5-flash-002: 8.659763097763062s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78814\n",
      "candidates_token_count: 597\n",
      "total_token_count: 79411\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58858\n",
      "Found 10 jobs on page 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:06:05,485 - INFO - Completion time of gemini-1.5-flash-002: 8.977699041366577s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80099\n",
      "candidates_token_count: 412\n",
      "total_token_count: 80511\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:06:16,491 - INFO - Completion time of gemini-1.5-flash-002: 8.815452814102173s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78749\n",
      "candidates_token_count: 573\n",
      "total_token_count: 79322\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:06:28,582 - INFO - Completion time of gemini-1.5-flash-002: 9.83709192276001s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78734\n",
      "candidates_token_count: 559\n",
      "total_token_count: 79293\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:06:38,344 - INFO - Completion time of gemini-1.5-flash-002: 7.548496961593628s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78739\n",
      "candidates_token_count: 447\n",
      "total_token_count: 79186\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:06:49,139 - INFO - Completion time of gemini-1.5-flash-002: 8.626811981201172s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78716\n",
      "candidates_token_count: 517\n",
      "total_token_count: 79233\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:06:59,196 - INFO - Completion time of gemini-1.5-flash-002: 7.798932075500488s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 81124\n",
      "candidates_token_count: 454\n",
      "total_token_count: 81578\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:07:09,227 - INFO - Completion time of gemini-1.5-flash-002: 7.853744029998779s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78987\n",
      "candidates_token_count: 459\n",
      "total_token_count: 79446\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:07:17,852 - INFO - Completion time of gemini-1.5-flash-002: 6.38678765296936s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78476\n",
      "candidates_token_count: 338\n",
      "total_token_count: 78814\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:07:29,470 - INFO - Completion time of gemini-1.5-flash-002: 9.353066205978394s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78668\n",
      "candidates_token_count: 499\n",
      "total_token_count: 79167\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:07:43,568 - INFO - Completion time of gemini-1.5-flash-002: 11.919336080551147s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78725\n",
      "candidates_token_count: 497\n",
      "total_token_count: 79222\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58588\n",
      "Found 10 jobs on page 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:07:57,238 - INFO - Completion time of gemini-1.5-flash-002: 7.170166015625s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80705\n",
      "candidates_token_count: 407\n",
      "total_token_count: 81112\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:08:09,379 - INFO - Completion time of gemini-1.5-flash-002: 9.941645860671997s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79034\n",
      "candidates_token_count: 663\n",
      "total_token_count: 79697\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:08:21,320 - INFO - Completion time of gemini-1.5-flash-002: 9.737260103225708s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79046\n",
      "candidates_token_count: 513\n",
      "total_token_count: 79559\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:08:31,823 - INFO - Completion time of gemini-1.5-flash-002: 8.338557004928589s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79054\n",
      "candidates_token_count: 532\n",
      "total_token_count: 79586\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:08:41,274 - INFO - Completion time of gemini-1.5-flash-002: 7.285199880599976s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78482\n",
      "candidates_token_count: 411\n",
      "total_token_count: 78893\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:08:52,302 - INFO - Completion time of gemini-1.5-flash-002: 8.865340948104858s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78710\n",
      "candidates_token_count: 453\n",
      "total_token_count: 79163\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:09:11,807 - INFO - Completion time of gemini-1.5-flash-002: 17.172494173049927s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79394\n",
      "candidates_token_count: 640\n",
      "total_token_count: 80034\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:09:20,839 - INFO - Completion time of gemini-1.5-flash-002: 6.834604024887085s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78487\n",
      "candidates_token_count: 390\n",
      "total_token_count: 78877\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:09:30,292 - INFO - Completion time of gemini-1.5-flash-002: 7.140509843826294s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80065\n",
      "candidates_token_count: 359\n",
      "total_token_count: 80424\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:09:39,554 - INFO - Completion time of gemini-1.5-flash-002: 6.93916392326355s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78279\n",
      "candidates_token_count: 339\n",
      "total_token_count: 78618\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58440\n",
      "Found 10 jobs on page 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:09:53,786 - INFO - Completion time of gemini-1.5-flash-002: 7.773674964904785s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78688\n",
      "candidates_token_count: 457\n",
      "total_token_count: 79145\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:10:17,839 - INFO - Completion time of gemini-1.5-flash-002: 21.84380006790161s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79468\n",
      "candidates_token_count: 1106\n",
      "total_token_count: 80574\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:10:28,882 - INFO - Completion time of gemini-1.5-flash-002: 8.790726900100708s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 82836\n",
      "candidates_token_count: 541\n",
      "total_token_count: 83377\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:10:43,299 - INFO - Completion time of gemini-1.5-flash-002: 12.22181510925293s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79004\n",
      "candidates_token_count: 795\n",
      "total_token_count: 79799\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:10:52,836 - INFO - Completion time of gemini-1.5-flash-002: 7.379441022872925s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78465\n",
      "candidates_token_count: 428\n",
      "total_token_count: 78893\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:11:04,649 - INFO - Completion time of gemini-1.5-flash-002: 9.645277976989746s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78938\n",
      "candidates_token_count: 561\n",
      "total_token_count: 79499\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:11:13,992 - INFO - Completion time of gemini-1.5-flash-002: 7.089282035827637s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78433\n",
      "candidates_token_count: 415\n",
      "total_token_count: 78848\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:11:25,669 - INFO - Completion time of gemini-1.5-flash-002: 9.405666589736938s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79635\n",
      "candidates_token_count: 640\n",
      "total_token_count: 80275\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:11:37,009 - INFO - Completion time of gemini-1.5-flash-002: 8.935020685195923s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78628\n",
      "candidates_token_count: 484\n",
      "total_token_count: 79112\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:11:47,969 - INFO - Completion time of gemini-1.5-flash-002: 8.758975982666016s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78645\n",
      "candidates_token_count: 520\n",
      "total_token_count: 79165\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58328\n",
      "Found 10 jobs on page 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:12:01,651 - INFO - Completion time of gemini-1.5-flash-002: 7.192215919494629s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78424\n",
      "candidates_token_count: 372\n",
      "total_token_count: 78796\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:12:11,476 - INFO - Completion time of gemini-1.5-flash-002: 7.628685235977173s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78693\n",
      "candidates_token_count: 475\n",
      "total_token_count: 79168\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:12:21,549 - INFO - Completion time of gemini-1.5-flash-002: 7.732708930969238s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78758\n",
      "candidates_token_count: 484\n",
      "total_token_count: 79242\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:12:32,471 - INFO - Completion time of gemini-1.5-flash-002: 8.549067974090576s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78550\n",
      "candidates_token_count: 532\n",
      "total_token_count: 79082\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:12:46,740 - INFO - Completion time of gemini-1.5-flash-002: 11.99820590019226s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79358\n",
      "candidates_token_count: 501\n",
      "total_token_count: 79859\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:12:56,825 - INFO - Completion time of gemini-1.5-flash-002: 7.397046089172363s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78483\n",
      "candidates_token_count: 349\n",
      "total_token_count: 78832\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:13:06,404 - INFO - Completion time of gemini-1.5-flash-002: 7.35339617729187s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78595\n",
      "candidates_token_count: 415\n",
      "total_token_count: 79010\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:13:17,734 - INFO - Completion time of gemini-1.5-flash-002: 9.164103746414185s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80504\n",
      "candidates_token_count: 561\n",
      "total_token_count: 81065\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:13:27,803 - INFO - Completion time of gemini-1.5-flash-002: 7.738248348236084s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78530\n",
      "candidates_token_count: 437\n",
      "total_token_count: 78967\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:13:36,672 - INFO - Completion time of gemini-1.5-flash-002: 6.646711111068726s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78326\n",
      "candidates_token_count: 370\n",
      "total_token_count: 78696\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58192\n",
      "Found 10 jobs on page 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:13:52,109 - INFO - Completion time of gemini-1.5-flash-002: 9.216200828552246s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79279\n",
      "candidates_token_count: 606\n",
      "total_token_count: 79885\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:14:08,317 - INFO - Completion time of gemini-1.5-flash-002: 13.70457410812378s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78461\n",
      "candidates_token_count: 359\n",
      "total_token_count: 78820\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:14:20,670 - INFO - Completion time of gemini-1.5-flash-002: 10.153227090835571s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 81160\n",
      "candidates_token_count: 708\n",
      "total_token_count: 81868\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:14:30,279 - INFO - Completion time of gemini-1.5-flash-002: 7.401612043380737s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 82854\n",
      "candidates_token_count: 401\n",
      "total_token_count: 83255\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:14:41,926 - INFO - Completion time of gemini-1.5-flash-002: 9.476279020309448s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78876\n",
      "candidates_token_count: 440\n",
      "total_token_count: 79316\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:14:51,940 - INFO - Completion time of gemini-1.5-flash-002: 7.734309196472168s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78405\n",
      "candidates_token_count: 455\n",
      "total_token_count: 78860\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:15:02,774 - INFO - Completion time of gemini-1.5-flash-002: 8.539802312850952s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78586\n",
      "candidates_token_count: 512\n",
      "total_token_count: 79098\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:15:13,069 - INFO - Completion time of gemini-1.5-flash-002: 8.052308082580566s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79179\n",
      "candidates_token_count: 526\n",
      "total_token_count: 79705\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:15:23,974 - INFO - Completion time of gemini-1.5-flash-002: 8.693143129348755s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78841\n",
      "candidates_token_count: 498\n",
      "total_token_count: 79339\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:15:34,801 - INFO - Completion time of gemini-1.5-flash-002: 8.653696060180664s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78483\n",
      "candidates_token_count: 403\n",
      "total_token_count: 78886\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 58006\n",
      "Found 10 jobs on page 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:15:48,194 - INFO - Completion time of gemini-1.5-flash-002: 7.168761968612671s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79070\n",
      "candidates_token_count: 397\n",
      "total_token_count: 79467\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 57988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:16:05,073 - INFO - Completion time of gemini-1.5-flash-002: 14.717318296432495s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78441\n",
      "candidates_token_count: 386\n",
      "total_token_count: 78827\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 57926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:16:19,823 - INFO - Completion time of gemini-1.5-flash-002: 12.404889822006226s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80716\n",
      "candidates_token_count: 589\n",
      "total_token_count: 81305\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 57915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:16:29,961 - INFO - Completion time of gemini-1.5-flash-002: 7.970347166061401s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78693\n",
      "candidates_token_count: 511\n",
      "total_token_count: 79204\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 57879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:16:39,812 - INFO - Completion time of gemini-1.5-flash-002: 7.667087078094482s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78675\n",
      "candidates_token_count: 388\n",
      "total_token_count: 79063\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 57873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:16:49,119 - INFO - Completion time of gemini-1.5-flash-002: 6.983450889587402s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78768\n",
      "candidates_token_count: 368\n",
      "total_token_count: 79136\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 57858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:16:58,505 - INFO - Completion time of gemini-1.5-flash-002: 7.178839683532715s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78302\n",
      "candidates_token_count: 386\n",
      "total_token_count: 78688\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 57843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:17:11,900 - INFO - Completion time of gemini-1.5-flash-002: 11.121387004852295s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78569\n",
      "candidates_token_count: 841\n",
      "total_token_count: 79410\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 57836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:17:23,800 - INFO - Completion time of gemini-1.5-flash-002: 9.613389730453491s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 86881\n",
      "candidates_token_count: 680\n",
      "total_token_count: 87561\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 57835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:17:35,080 - INFO - Completion time of gemini-1.5-flash-002: 9.040120124816895s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78618\n",
      "candidates_token_count: 464\n",
      "total_token_count: 79082\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 57832\n",
      "Found 10 jobs on page 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:17:48,564 - INFO - Completion time of gemini-1.5-flash-002: 6.833628177642822s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78719\n",
      "candidates_token_count: 374\n",
      "total_token_count: 79093\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 57815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:17:58,589 - INFO - Completion time of gemini-1.5-flash-002: 7.869045972824097s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80062\n",
      "candidates_token_count: 514\n",
      "total_token_count: 80576\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 57806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:18:08,786 - INFO - Completion time of gemini-1.5-flash-002: 7.872179985046387s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 79301\n",
      "candidates_token_count: 488\n",
      "total_token_count: 79789\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 57789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:18:19,260 - INFO - Completion time of gemini-1.5-flash-002: 7.577703237533569s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78857\n",
      "candidates_token_count: 454\n",
      "total_token_count: 79311\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 57740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:18:29,493 - INFO - Completion time of gemini-1.5-flash-002: 7.910138130187988s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80971\n",
      "candidates_token_count: 459\n",
      "total_token_count: 81430\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 57730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:18:43,500 - INFO - Completion time of gemini-1.5-flash-002: 11.498727798461914s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78930\n",
      "candidates_token_count: 874\n",
      "total_token_count: 79804\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 57721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:18:56,653 - INFO - Completion time of gemini-1.5-flash-002: 10.711904048919678s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78759\n",
      "candidates_token_count: 460\n",
      "total_token_count: 79219\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 57706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:19:07,392 - INFO - Completion time of gemini-1.5-flash-002: 8.353074789047241s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 80881\n",
      "candidates_token_count: 518\n",
      "total_token_count: 81399\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 43915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:19:16,662 - INFO - Completion time of gemini-1.5-flash-002: 7.095476865768433s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78930\n",
      "candidates_token_count: 391\n",
      "total_token_count: 79321\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 43194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 18:19:27,841 - INFO - Completion time of gemini-1.5-flash-002: 8.476579904556274s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_token_count: 78931\n",
      "candidates_token_count: 568\n",
      "total_token_count: 79499\n",
      "\n",
      "Appended job detail to DataFrame.\n",
      "Processed job ID: 57671\n",
      "Data saved to CSV.\n",
      "Data saved to test_topjob.csv\n"
     ]
    }
   ],
   "source": [
    "scraper = JobScraperr(base_url=\"https://topjobvn.com/vi/jobs/page/\", output_csv=\"test_topjob.csv\")\n",
    "scraper.crawl_jobs(start_page=1, end_page=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scraper.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "placeholders = ['Not available', 'No requirement', 'Not required', \"No experience\", \"No degree\", \"No certificate\",\"not available\"]\n",
    "df.replace(placeholders, \"No requirement\", inplace=True)\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    return text.replace(\"\\n\", \" \").replace(\"\\t\", \" \").strip().lower()\n",
    "\n",
    "columns_to_clean = [\n",
    "    \"Candidate_Experience_Requirements\",\n",
    "    \"Candidate_soft_skill_Requirements\",\n",
    "    \"Candidate_technical_skill_Requirements\",\n",
    "    \"Candidate_degree_Requirements\"\n",
    "]\n",
    "\n",
    "for col in columns_to_clean:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_text)\n",
    "\n",
    "date_columns = [\"Job_Date-open\", \"Job_Date-end\"]\n",
    "for col in date_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].str.replace(\" \", \"-\", regex=False)\n",
    "\n",
    "def extract_min_salary(salary):\n",
    "    if pd.isna(salary):\n",
    "        return pd.NA\n",
    "    numbers = [int(num.replace(',', '')) for num in salary.split() if num.replace(',', '').isdigit()]\n",
    "    return numbers[0] if numbers else pd.NA\n",
    "\n",
    "df['Salary_Min'] = df['Salary'].apply(extract_min_salary)\n",
    "df['Salary_Min'] = pd.to_numeric(df['Salary_Min'], errors='coerce').astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"topjob.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/llm-embedder\")\n",
    "model_embed = AutoModel.from_pretrained(\"BAAI/llm-embedder\")\n",
    "model_embed.eval()\n",
    "\n",
    "def last_token_pool(last_hidden_states: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])  \n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "def embed_text(text):\n",
    "    if pd.isna(text) or text.lower().strip() == \"no requirement\":\n",
    "        return \"no requirement\"  \n",
    "    inputs = tokenizer(str(text), return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        out = model_embed(**inputs)\n",
    "        embeddings = last_token_pool(out.last_hidden_state, inputs['attention_mask'])\n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    return embeddings.tolist()\n",
    "\n",
    "file_path = '/Users/duongphuonggiang/Documents/VietCvProcessor/crawl/topjob.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Candidate_Experience_Requirements:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Candidate_Experience_Requirements:  16%|█▌        | 31/200 [00:02<00:13, 12.57it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     tqdm\u001b[38;5;241m.\u001b[39mpandas(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df[col_name]\u001b[38;5;241m.\u001b[39mprogress_apply(embed_text)\n\u001b[0;32m---> 13\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCandidate_Experience_Requirements_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_embedding_for_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCandidate_Experience_Requirements\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCandidate_soft_skill_Requirements_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m generate_embedding_for_column(df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCandidate_soft_skill_Requirements\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCandidate_technical_skill_Requirements_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m generate_embedding_for_column(df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCandidate_technical_skill_Requirements\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m, in \u001b[0;36mgenerate_embedding_for_column\u001b[0;34m(df, col_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_embedding_for_column\u001b[39m(df, col_name):\n\u001b[1;32m     10\u001b[0m     tqdm\u001b[38;5;241m.\u001b[39mpandas(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43membed_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/std.py:917\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/std.py:912\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 27\u001b[0m, in \u001b[0;36membed_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     25\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(\u001b[38;5;28mstr\u001b[39m(text), return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 27\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m last_token_pool(out\u001b[38;5;241m.\u001b[39mlast_hidden_state, inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     29\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(embeddings, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    575\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:515\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    507\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 515\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    525\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:395\u001b[0m, in \u001b[0;36mBertSdpaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m    384\u001b[0m         hidden_states,\n\u001b[1;32m    385\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         output_attentions,\n\u001b[1;32m    391\u001b[0m     )\n\u001b[1;32m    393\u001b[0m bsz, tgt_len, _ \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m--> 395\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# If this is instantiated as a cross-attention module, the keys and values come from an encoder; the attention\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# mask needs to be such that the encoder's padding tokens are not attended to.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m is_cross_attention \u001b[38;5;241m=\u001b[39m encoder_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "placeholders = ['Not available', 'No requirement', 'Not required', \"No experience\", \"No degree\", \"No certificate\"]\n",
    "df.replace(placeholders, pd.NA, inplace=True)\n",
    "\n",
    "def generate_embedding_for_column(df, col_name):\n",
    "    tqdm.pandas(desc=f\"Embedding {col_name}\")\n",
    "    return df[col_name].progress_apply(embed_text)\n",
    "\n",
    "df[\"Candidate_Experience_Requirements_embedding\"] = generate_embedding_for_column(df, \"Candidate_Experience_Requirements\")\n",
    "df[\"Candidate_soft_skill_Requirements_embedding\"] = generate_embedding_for_column(df, \"Candidate_soft_skill_Requirements\")\n",
    "df[\"Candidate_technical_skill_Requirements_embedding\"] = generate_embedding_for_column(df, \"Candidate_technical_skill_Requirements\")\n",
    "df[\"Candidate_degree_Requirements_embedding\"] = generate_embedding_for_column(df, \"Candidate_degree_Requirements\")\n",
    "\n",
    "def create_mappings(df):\n",
    "    mappings = []\n",
    "    for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Creating mappings\"):\n",
    "        job_info = {\n",
    "            \"JOB_ID\": row.get(\"Job ID\"),\n",
    "            \"location\": row.get(\"Job_Location\"),\n",
    "            \"date_opened\": row.get(\"Job_Date-open\"),\n",
    "            \"deadline\": row.get(\"Job_Date-end\"),\n",
    "            \"title\": row.get(\"Title\"),\n",
    "            \"description\": row.get(\"Candidate_Experience_Requirements\"),\n",
    "            \"companyID\": row.get(\"Job ID\"),\n",
    "            \"job information\": {\n",
    "                \"experience_embedding\": row.get(\"Candidate_Experience_Requirements_embedding\", \"no requirement\"),\n",
    "                \"soft_skill_embedding\": row.get(\"Candidate_soft_skill_Requirements_embedding\", \"no requirement\"),\n",
    "                \"technical_skill_embedding\": row.get(\"Candidate_technical_skill_Requirements_embedding\", \"no requirement\"),\n",
    "                \"degree_embedding\": row.get(\"Candidate_degree_Requirements_embedding\", \"no requirement\")\n",
    "            },\n",
    "            \"workingType\": row.get(\"Job_Type\"),\n",
    "            \"workingTime\": row.get(\"Job_Category\"),\n",
    "            \"salary_month\": row.get(\"Salary_Min\"),\n",
    "            \"sectorID\": row.get(\"Job ID\"),\n",
    "        }\n",
    "        mappings.append({\"mappings\": {\"properties\": job_info}})\n",
    "    \n",
    "    return mappings\n",
    "\n",
    "job_mappings = create_mappings(df)\n",
    "\n",
    "output_dir = 'crawl'\n",
    "output_file = os.path.join(output_dir, 'job_mappings.json')\n",
    "os.makedirs(output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
